{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unittest.mock import MagicMock, patch\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, to_json, udf, explode, avg, count, trim, lower, length, max as spark_max\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType, DoubleType, ArrayType,\n",
    "    LongType, FloatType, DateType, TimestampType\n",
    ")\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"TestSession\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy DataFrame\n",
    "data = [(\"Agency A\", \"Software Engineer\", \"Civil Title\", \"Tech\", \"2023-06-01\", 60000, 80000, \"Bachelor's degree required\", \"Python; SQL\")]\n",
    "schema = StructType([\n",
    "    StructField(\"agency\", StringType(), True),\n",
    "    StructField(\"businessTitle\", StringType(), True),\n",
    "    StructField(\"civilServiceTitle\", StringType(), True),\n",
    "    StructField(\"jobCategory\", StringType(), True),\n",
    "    StructField(\"postingDate\", StringType(), True),\n",
    "    StructField(\"salaryRangeFrom\", IntegerType(), True),\n",
    "    StructField(\"salaryRangeTo\", IntegerType(), True),\n",
    "    StructField(\"minimumQualRequirements\", StringType(), True),\n",
    "    StructField(\"preferredSkills\", StringType(), True)\n",
    "])\n",
    "df = spark.createDataFrame(data, schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestJobPipelineComponents(unittest.TestCase):\n",
    "\n",
    "    def test_spark_factory(self):\n",
    "        session = SparkFactory.create(\"TestApp\")\n",
    "        self.assertIsInstance(session, SparkSession)\n",
    "\n",
    "    def test_job_data_extractor(self):\n",
    "        path = \"/tmp/test_input.csv\"\n",
    "        df.toPandas().to_csv(path, index=False)\n",
    "        extractor = JobDataExtractor(spark, path)\n",
    "        result = extractor.read()\n",
    "        self.assertIsNotNone(result)\n",
    "        self.assertGreater(len(result.columns), 0)\n",
    "\n",
    "    def test_job_data_wrangler(self):\n",
    "        wrangler = JobDataWrangler(df)\n",
    "        result = wrangler.sanitize_column_names()\n",
    "        for col_name in result.columns:\n",
    "            self.assertFalse(re.search(r\"[^\\w]\", col_name))\n",
    "\n",
    "    def test_job_data_transformer(self):\n",
    "        transformer = JobDataTransformer(df)\n",
    "        result = transformer.transform()\n",
    "        self.assertIn(\"avgSalary\", result.columns)\n",
    "        self.assertIn(\"degreeLevel\", result.columns)\n",
    "        self.assertIn(\"skillsJson\", result.columns)\n",
    "\n",
    "    def test_job_data_validator(self):\n",
    "        transformer = JobDataTransformer(df)\n",
    "        transformed = transformer.transform()\n",
    "        validator = JobDataValidator(transformed)\n",
    "        validated = validator.validate()\n",
    "        self.assertTrue(validated.count() > 0)\n",
    "\n",
    "    def test_job_data_loader(self):\n",
    "        transformer = JobDataTransformer(df)\n",
    "        transformed = transformer.transform()\n",
    "        loader = JobDataLoader(transformed)\n",
    "        output_path = \"/tmp/test_output\"\n",
    "        loader.write(output_path)\n",
    "        self.assertTrue(os.path.exists(output_path))\n",
    "\n",
    "    def test_job_data_profiler(self):\n",
    "        profiler = JobDataProfiler(df)\n",
    "        profiler.detect_column_types()\n",
    "        self.assertGreaterEqual(len(profiler.categorical_cols + profiler.numerical_cols + profiler.date_cols), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unittest.TextTestRunner().run(unittest.defaultTestLoader.loadTestsFromTestCase(TestJobPipelineComponents))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
